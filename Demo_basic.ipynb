{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehend API  invoke  API Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook shows how to use Comprehend Sentiment API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install boto3==1.7.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure boto3 client for comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "client = boto3.client('comprehend')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Comprehend  api which accepts a single doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"This is an amazing place\"\n",
    "language_code ='en' # Language code for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.detect_sentiment(Text=text, LanguageCode=language_code)\n",
    "sentiment = response[\"Sentiment\"]\n",
    "confidence_score = response[\"SentimentScore\"][sentiment.title()]\n",
    "\n",
    "print( \"The sentiment for \\\" {} \\\" is: {}, with score {}\".format(text, sentiment, confidence_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's  test the Comprehend batch api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_doc =[\n",
    "     \"simplistic , silly and tedious\" \n",
    ", \"it's so laddish and juvenile , only teenage boys could possibly find it funny .\"\n",
    ", \"exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable .\"\n",
    ", \"perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .\"\n",
    ", \"steers turns in a snappy screenplay that curls at the edges ; it's so clever you want to hate it . but he somehow pulls it off .\"\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.batch_detect_sentiment(TextList=list_of_doc, LanguageCode=language_code)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets test the Comprehend Async Api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a bucket in this account you have access to\n",
    "2. Create an IAM Service Role for Comprehend to have read and write access to your bucket. The quickest way to make this happen is go to the comprehend console -> Try comprehend -> Analysis-> Create analysis job. Submit a dummy job and copy paste the role ARN it created in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name=\"aegovansagemaker\"\n",
    "role='arn:aws:iam::<AccountId>:role/service-role/<RoleName?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download public movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\n",
    "! tar -xf \"rt-polaritydata.tar.gz\" \n",
    "! ls rt-polaritydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_file='rt-polaritydata/rt-polarity.pos'\n",
    "local_file_converted='rt-polaritydata/rt-polarity.pos.utf8.txt'\n",
    "s3_input_dir = 'rt-polaritydata'\n",
    "s3_input_key = '{}/{}'.format(s3_input_dir, 'rt-polarity.pos.utf8.txt')\n",
    "s3_output_key = 's3://{}'.format(bucket_name) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprehend API only accepts UTF-8 formatted documents .., so convert the file which uses latin encoding to utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_utf8(sourcefile, destinationfile, source_encoding):\n",
    "    with open(local_file, 'r', encoding=source_encoding) as input:\n",
    "         with open(local_file_converted, 'w', encoding=\"utf-8\") as out:\n",
    "            for line in input:\n",
    "                out.write(line[:-1]+'\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the converted file to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s3 = boto3.resource('s3')\n",
    "convert_to_utf8(local_file, local_file, 'latin')\n",
    "with open(local_file_converted, 'rb') as data:\n",
    "    s3.Bucket(bucket_name).put_object(Key=s3_input_key, Body=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a comprehend sentiment analysis job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import uuid\n",
    "job_name = 'start_sentiment_detection_job' + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "request_id = str(uuid.uuid4())\n",
    "\n",
    "\n",
    "response = client.start_sentiment_detection_job(\n",
    "    InputDataConfig={\n",
    "        'S3Uri': 's3://{}/{}'.format(bucket_name, s3_input_dir),\n",
    "        'InputFormat': 'ONE_DOC_PER_LINE'\n",
    "    },\n",
    "    OutputDataConfig={\n",
    "        'S3Uri': s3_output_key,\n",
    "    },\n",
    "    DataAccessRoleArn=role,\n",
    "    JobName=job_name,\n",
    "    LanguageCode='en',\n",
    "    ClientRequestToken=request_id\n",
    ")\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the status of the job until it is complete or failed. This will take atleast 10 minutes to complete.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "import time\n",
    "is_complete = False\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "while not is_complete:\n",
    "    response_describe = client.describe_sentiment_detection_job(JobId=response['JobId'])\n",
    "    job_status = response_describe['SentimentDetectionJobProperties']['JobStatus']\n",
    "    if  job_status in  ['SUBMITTED', 'IN_PROGRESS']:\n",
    "        ## Comprehend is still working through.. sleep and try again\n",
    "        print(\"{} job is in status {}...\".format(strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime()), job_status))\n",
    "        time.sleep(10)     \n",
    "        continue\n",
    "    else:\n",
    "        is_complete = True\n",
    "        \n",
    "\n",
    "print (\" The job completed with code {}\".format(job_status))\n",
    "pp.pprint(response_describe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
